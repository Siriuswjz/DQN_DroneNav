# 基于DQN的无人机自主导航

本项目实现了基于深度Q网络（Deep Q-Network, DQN）的无人机自主导航系统，在AirSim仿真环境中学习穿越圆形洞口，实现自主避障与精确导航。

## 项目概述

无人机需要在仿真环境中学习穿越一系列圆形洞口，避免与障碍物碰撞。系统采用VGG16作为特征提取器，结合注意力机制从RGB图像中提取空间特征，通过DQN算法学习最优飞行策略。

## 主要特性

- **深度强化学习**：基于DQN算法，结合经验回放和目标网络稳定训练
- **视觉导航**：从50×50×3 RGB图像中学习导航策略
- **注意力机制**：引入空间注意力模块，提升对洞口位置的感知能力
- **迁移学习**：使用ImageNet预训练的VGG16权重，加速收敛
- **两阶段训练**：单洞训练建立基础技能，多洞训练提升连续穿越能力

## 环境要求

- Python 3.7+
- PyTorch 1.7.1
- Stable-Baselines3 1.2.0
- Microsoft AirSim
- Unreal Engine 4

## 安装

```bash
pip install -r requirements.txt
```

## 项目结构

```
.
├── dqn/                    # DQN算法实现
│   ├── train.py           # 训练脚本
│   └── test.py            # 测试脚本
├── scripts/               # 环境配置
│   ├── airsim_env.py      # AirSim环境封装
│   ├── env.py             # 自定义环境
│   └── config.yml         # 配置文件
├── figures/               # 训练结果图表
├── tb_logs/               # TensorBoard日志
└── run.py                 # 主运行脚本
```

## 使用方法

### 训练模型

```bash
python run.py
```

### 测试模型

```bash
python dqn/test.py
```

## 实验结果

### 单洞训练（第一阶段）

- 训练步数：500,000步
- 平均穿洞数：6个
- 最大穿洞数：25个
- 单洞成功率：60-70%

### 多洞训练（第二阶段）

- 训练步数：600,000步
- 平均穿洞数：4个
- 最大穿洞数：10个

## 技术亮点

1. **特征提取优化**
   - 使用VGG16预训练权重进行迁移学习
   - 引入空间注意力机制增强感知能力
   - 分层微调策略防止过拟合

2. **训练策略**
   - 经验回放机制提高样本利用效率
   - 目标网络稳定Q值估计
   - 评估驱动的模型保存策略
   - 支持断点续训

3. **奖励函数设计**
   - 综合考虑目标接近度、对齐精度和任务完成情况
   - 平衡探索与利用的奖励机制
